{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Christheoneoneil/stat330_final/blob/model_fitting/model_fitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b06MBAFmSIfx"
      },
      "source": [
        "# Relevant Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYc-479GPZAa",
        "outputId": "bf7db753-8c68-46f6-a829-b14c7f2aa209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nest_asyncio in /home/mitch/miniconda3/envs/bayes/lib/python3.9/site-packages (1.5.5)\n"
          ]
        }
      ],
      "source": [
        "import stan\n",
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import arviz as az\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_b-TZPNUgDv"
      },
      "source": [
        "# Preliminary Code Cleaning for Multinomial Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nIwv-ZxRU47Q"
      },
      "outputs": [],
      "source": [
        "def read_data(file_name: str):\n",
        "  \"\"\"\n",
        "  param filename: name of data file\n",
        "  returns: pandas data frame\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(file_name, index_col = \"Unnamed: 0\")\n",
        "  df.dropna(axis = 0, how=\"any\", inplace=True)\n",
        "  df = df.loc[:,~df.columns.duplicated()]\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T2N019nSWTZ7"
      },
      "outputs": [],
      "source": [
        "def prep_data(df: pd.DataFrame, key: str, unwanted_cols: list):\n",
        "  \"\"\"\n",
        "  param df: data frame that needs to be formatted\n",
        "  key: key value associated with provided dictionary\n",
        "  unwanted_cols: columns that are ultimatly not needed for analysis\n",
        "  returns: prept data frame for logit regression\n",
        "  \"\"\"\n",
        "  from sklearn import preprocessing\n",
        "  df_copy = df.copy()\n",
        "  unnormed_cols = [\"STUDWGT\"]\n",
        "\n",
        "  if key == \"imputed\":\n",
        "    unnormed_cols = ['ACTComposite', 'SATMath', \n",
        "                     'SATVerbal', 'SATWriting'] + unnormed_cols\n",
        "    df_copy.drop(columns=[\"Unnamed: 0.1\"], inplace=True)\n",
        "\n",
        "  normalizer = preprocessing.MinMaxScaler()\n",
        "  normed_cols = normalizer.fit_transform(df[unnormed_cols])\n",
        "  df_copy[unnormed_cols] = normed_cols\n",
        "  df_copy.drop(columns=unwanted_cols, inplace=True)\n",
        "\n",
        "  recode_vars = [\"STRAT\", \"SELECTIVITY\", \"DOBYear\"]\n",
        "  for var in recode_vars:\n",
        "    unencoded_list = list(df_copy[var].unique())\n",
        "    encode_list = list(range(1, len(unencoded_list)+1))\n",
        "    df_copy[var].replace(unencoded_list, encode_list, inplace=True)\n",
        "  return(df_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "XD69j_rfUfm8",
        "outputId": "fe89324a-68cf-44c7-c687-5b911c0b13b6"
      },
      "outputs": [],
      "source": [
        "df_dict = {\"imputed\": read_data(\"data/final_frame_imputed.csv\"),\n",
        "           \"non_imputed\": read_data(\"data/final_frame_non_imputed.csv\")}\n",
        "unnecessary_cols = [\"ACERECODE\"]\n",
        "for key, df in df_dict.items():\n",
        "  df_dict[key] = prep_data(df, key, unnecessary_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvRIiikxSlhT"
      },
      "source": [
        "# Setting Up Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k_zUYXChSbJZ"
      },
      "outputs": [],
      "source": [
        "def fit_model(model_code: str, X: np.array, Y: np.array, n: int, k: int, \n",
        "              flag_val: int):\n",
        "  \"\"\"\n",
        "  param model_code: stan formatted code for model\n",
        "  param X: nxk array of covariates \n",
        "  param Y: array of target values\n",
        "  param n: number of rows \n",
        "  param k: number of covarites\n",
        "  param flag_val: do predictive distrub flag value\n",
        "  reutrns: stan sampler object\n",
        "  \"\"\"\n",
        "  mod = stan.build(model_code,data={\"X\": X, \"Y\": Y, \"n\": n, \"k\": k, \n",
        "                               \"do_prior_predictive\": flag_val})\n",
        "  samples = mod.sample()\n",
        "  return samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8-lYrQWBUgwq"
      },
      "outputs": [],
      "source": [
        "multinomial_log_stan_code = \"\"\"\n",
        "data {\n",
        "  int<lower=0> n;                // number of units\n",
        "  int<lower=0> k;                // number of covariates\n",
        "  matrix[n, k] X;            // covariates for each entry, including the intercept covariate\n",
        "  int<lower=1,upper=5> Y[n];     // categorical\n",
        "\n",
        "  int do_prior_predictive;\n",
        "}\n",
        "parameters {\n",
        "  vector[k] beta;\n",
        "  vector<lower=0>[k] lambda;\n",
        "  real<lower=0> tau;\n",
        "  real<lower=0> sigma;            // the coefficients\n",
        "}\n",
        "\n",
        "transformed parameters {\n",
        "  vector[n] mu;\n",
        "  vector[n] eta;                // linear predictors\n",
        "  eta = X * beta;\n",
        "  mu = inv_logit(eta);\n",
        "}\n",
        "model {\n",
        "  lambda ~ cauchy(0, 1);\n",
        "  tau ~ cauchy(0, 1);\n",
        "  for (i in 1:k) {\n",
        "    beta[i] ~ normal(0, lambda[i] * tau);\n",
        "  }\n",
        "  if (do_prior_predictive != 1) {\n",
        "    for (i in 1:n) {\n",
        "      Y[i] ~ categorical_logit_glm(mu);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "generated quantities {\n",
        "  int<lower=1,upper=4> Y_tilde[n];\n",
        "  for (i in 1:n) {\n",
        "    Y_tilde[i] = categorical_logit_glm_rng(mu);  \n",
        "  } \n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FICIRLDwVXAL"
      },
      "outputs": [],
      "source": [
        "target_col = \"choice\"\n",
        "prior_pred_dict = {}\n",
        "for key, df in df_dict.items():\n",
        "  df = df.sample(frac=0.20)\n",
        "  covars = [cov for cov in list(df.columns) if cov not in target_col]\n",
        "  x = np.array(df[covars])\n",
        "  n = len(x)\n",
        "  x = np.concatenate((np.ones((n, 1)), x), axis=1)\n",
        "  y = np.array(df[target_col], dtype=\"int64\")\n",
        "  k = x.shape[1]\n",
        "  prior_pred_dict[key] = fit_model(multinomial_log_stan_code, x, y, n, k, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2022-11-18 LASSO Attempt-maj\n",
        "model_code = \"\"\"\n",
        "data {\n",
        "    int<lower=1> num_classes;\n",
        "    int<lower=0> n;\n",
        "    int<lower=0> k;\n",
        "    matrix[n, k] x;\n",
        "    array[n] int<lower=1, upper=num_classes> y;\n",
        "\n",
        "    int do_prior_predictive;\n",
        "}\n",
        "parameters {\n",
        "    vector<lower=0>[num_classes] alpha;\n",
        "    matrix[k, num_classes] beta;\n",
        "    vector<lower=0>[k] lambda;\n",
        "    real<lower=0> tau;\n",
        "}\n",
        "model {\n",
        "    alpha ~ lognormal(0,1);\n",
        "    lambda ~ cauchy(0,1);\n",
        "    tau ~ cauchy(0,1);\n",
        "    for (i in 1:k) {\n",
        "        beta[i] ~ normal(0, lambda[i] * tau);\n",
        "    }\n",
        "    if (do_prior_predictive != 1) {\n",
        "        y ~ categorical_logit_glm(x, alpha, beta);\n",
        "    }\n",
        "}\n",
        "generated quantities {\n",
        "    array[n] real Y_tilde_1;\n",
        "    array[n] real Y_tilde_2;\n",
        "    array[n] real Y_tilde_3;\n",
        "    array[n] real Y_tilde_4;\n",
        "    for (i in 1:n){\n",
        "        Y_tilde_1[i] = categorical_logit_glm_lpmf(1 | x[i, :], alpha, beta);\n",
        "        Y_tilde_2[i] = categorical_logit_glm_lpmf(2 | x[i, :], alpha, beta);\n",
        "        Y_tilde_3[i] = categorical_logit_glm_lpmf(3 | x[i, :], alpha, beta);\n",
        "        Y_tilde_4[i] = categorical_logit_glm_lpmf(4 | x[i, :], alpha, beta);\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df_dict['imputed']\n",
        "target_col = \"CHOICE\"\n",
        "df_sub = df.sample(frac=0.10)\n",
        "y = df_sub[target_col].to_numpy(dtype=np.int16)\n",
        "x = df_sub.drop(target_col, axis=1).to_numpy()\n",
        "num_classes = len(np.unique(y))\n",
        "n = x.shape[0]\n",
        "k = x.shape[1]\n",
        "\n",
        "model = stan.build(model_code, {'num_classes':num_classes, 'n':n, 'k':k, 'x':x, 'y':y, 'do_prior_predictive':1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Sampling:   0%\n",
            "Sampling:   0% (1/8000)\n",
            "Sampling:   0% (2/8000)\n",
            "Sampling:   0% (3/8000)\n",
            "Sampling:   1% (102/8000)\n",
            "Sampling:   1% (103/8000)\n",
            "Sampling:   3% (202/8000)\n",
            "Sampling:   4% (301/8000)\n",
            "Sampling:   5% (401/8000)\n",
            "Sampling:   6% (500/8000)\n",
            "Sampling:   8% (600/8000)\n",
            "Sampling:   9% (700/8000)\n",
            "Sampling:  10% (800/8000)\n",
            "Sampling:  11% (900/8000)\n",
            "Sampling:  12% (1000/8000)\n",
            "Sampling:  14% (1100/8000)\n",
            "Sampling:  15% (1200/8000)\n",
            "Sampling:  16% (1300/8000)\n",
            "Sampling:  18% (1400/8000)\n",
            "Sampling:  19% (1500/8000)\n",
            "Sampling:  20% (1600/8000)\n",
            "Sampling:  21% (1700/8000)\n",
            "Sampling:  22% (1800/8000)\n",
            "Sampling:  24% (1900/8000)\n",
            "Sampling:  25% (2000/8000)\n",
            "Sampling:  26% (2100/8000)\n",
            "Sampling:  28% (2200/8000)\n",
            "Sampling:  29% (2300/8000)\n",
            "Sampling:  30% (2400/8000)\n",
            "Sampling:  31% (2500/8000)\n",
            "Sampling:  32% (2600/8000)\n",
            "Sampling:  34% (2700/8000)\n",
            "Sampling:  35% (2800/8000)\n",
            "Sampling:  36% (2900/8000)\n",
            "Sampling:  38% (3000/8000)\n",
            "Sampling:  39% (3100/8000)\n",
            "Sampling:  40% (3200/8000)\n",
            "Sampling:  41% (3300/8000)\n",
            "Sampling:  43% (3401/8000)\n",
            "Sampling:  44% (3501/8000)\n",
            "Sampling:  45% (3601/8000)\n",
            "Sampling:  46% (3701/8000)\n",
            "Sampling:  48% (3802/8000)\n",
            "Sampling:  49% (3903/8000)\n",
            "Sampling:  50% (4004/8000)\n",
            "Sampling:  51% (4103/8000)\n",
            "Sampling:  53% (4202/8000)\n",
            "Sampling:  54% (4301/8000)\n",
            "Sampling:  55% (4400/8000)\n",
            "Sampling:  56% (4500/8000)\n",
            "Sampling:  58% (4600/8000)\n",
            "Sampling:  59% (4700/8000)\n",
            "Sampling:  60% (4800/8000)\n",
            "Sampling:  61% (4900/8000)\n",
            "Sampling:  62% (5000/8000)\n",
            "Sampling:  64% (5100/8000)\n",
            "Sampling:  65% (5200/8000)\n",
            "Sampling:  66% (5300/8000)\n",
            "Sampling:  68% (5400/8000)\n",
            "Sampling:  69% (5500/8000)\n",
            "Sampling:  70% (5600/8000)\n",
            "Sampling:  71% (5700/8000)\n",
            "Sampling:  72% (5800/8000)\n",
            "Sampling:  74% (5900/8000)\n",
            "Sampling:  75% (6000/8000)\n",
            "Sampling:  76% (6100/8000)\n",
            "Sampling:  78% (6200/8000)\n",
            "Sampling:  79% (6300/8000)\n",
            "Sampling:  80% (6400/8000)\n",
            "Sampling:  81% (6500/8000)\n",
            "Sampling:  82% (6600/8000)\n",
            "Sampling:  84% (6700/8000)\n",
            "Sampling:  85% (6800/8000)\n",
            "Sampling:  86% (6900/8000)\n",
            "Sampling:  88% (7000/8000)\n",
            "Sampling:  89% (7100/8000)\n",
            "Sampling:  90% (7200/8000)\n",
            "Sampling:  91% (7300/8000)\n",
            "Sampling:  92% (7400/8000)\n",
            "Sampling:  94% (7500/8000)\n",
            "Sampling:  95% (7600/8000)\n",
            "Sampling:  96% (7700/8000)\n",
            "Sampling:  98% (7800/8000)\n",
            "Sampling:  99% (7900/8000)\n",
            "Sampling: 100% (8000/8000)\n",
            "Sampling: 100% (8000/8000), done.\n",
            "Messages received during sampling:\n",
            "  Gradient evaluation took 3.8e-05 seconds\n",
            "  1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.\n",
            "  Adjust your expectations accordingly!\n",
            "  Gradient evaluation took 4e-05 seconds\n",
            "  1000 transitions using 10 leapfrog steps per transition would take 0.4 seconds.\n",
            "  Adjust your expectations accordingly!\n",
            "  Gradient evaluation took 4.1e-05 seconds\n",
            "  1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.\n",
            "  Adjust your expectations accordingly!\n",
            "  Gradient evaluation took 4e-05 seconds\n",
            "  1000 transitions using 10 leapfrog steps per transition would take 0.4 seconds.\n",
            "  Adjust your expectations accordingly!\n"
          ]
        }
      ],
      "source": [
        "fit = model.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<stan.Fit>\n",
              "Parameters:\n",
              "    alpha: (4,)\n",
              "    beta: (79, 4)\n",
              "    lambda: (79,)\n",
              "    tau: ()\n",
              "    Y_tilde_1: (9858,)\n",
              "    Y_tilde_2: (9858,)\n",
              "    Y_tilde_3: (9858,)\n",
              "    Y_tilde_4: (9858,)\n",
              "Draws: 4000"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1191.0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check divergences\n",
        "np.sum(fit['divergent__'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fit.to_frame().to_csv(\"data/lasso_fit.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sd</th>\n",
              "      <th>hdi_3%</th>\n",
              "      <th>hdi_97%</th>\n",
              "      <th>mcse_mean</th>\n",
              "      <th>mcse_sd</th>\n",
              "      <th>ess_bulk</th>\n",
              "      <th>ess_tail</th>\n",
              "      <th>r_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>alpha[0]</th>\n",
              "      <td>1.318</td>\n",
              "      <td>1.711</td>\n",
              "      <td>0.040</td>\n",
              "      <td>4.170</td>\n",
              "      <td>0.212</td>\n",
              "      <td>0.150</td>\n",
              "      <td>17.0</td>\n",
              "      <td>602.0</td>\n",
              "      <td>1.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alpha[1]</th>\n",
              "      <td>1.779</td>\n",
              "      <td>1.839</td>\n",
              "      <td>0.058</td>\n",
              "      <td>4.308</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.093</td>\n",
              "      <td>48.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alpha[2]</th>\n",
              "      <td>1.484</td>\n",
              "      <td>2.154</td>\n",
              "      <td>0.054</td>\n",
              "      <td>4.634</td>\n",
              "      <td>0.162</td>\n",
              "      <td>0.115</td>\n",
              "      <td>18.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>1.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alpha[3]</th>\n",
              "      <td>1.420</td>\n",
              "      <td>1.902</td>\n",
              "      <td>0.028</td>\n",
              "      <td>4.073</td>\n",
              "      <td>0.124</td>\n",
              "      <td>0.088</td>\n",
              "      <td>340.0</td>\n",
              "      <td>645.0</td>\n",
              "      <td>1.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beta[0, 0]</th>\n",
              "      <td>0.757</td>\n",
              "      <td>2.532</td>\n",
              "      <td>-1.831</td>\n",
              "      <td>5.462</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.641</td>\n",
              "      <td>14.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y_tilde_4[9853]</th>\n",
              "      <td>-93.933</td>\n",
              "      <td>157.830</td>\n",
              "      <td>-303.084</td>\n",
              "      <td>0.000</td>\n",
              "      <td>19.874</td>\n",
              "      <td>14.118</td>\n",
              "      <td>87.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y_tilde_4[9854]</th>\n",
              "      <td>-109.316</td>\n",
              "      <td>193.856</td>\n",
              "      <td>-481.516</td>\n",
              "      <td>0.000</td>\n",
              "      <td>37.510</td>\n",
              "      <td>26.819</td>\n",
              "      <td>127.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y_tilde_4[9855]</th>\n",
              "      <td>-139.886</td>\n",
              "      <td>276.712</td>\n",
              "      <td>-506.140</td>\n",
              "      <td>0.000</td>\n",
              "      <td>46.625</td>\n",
              "      <td>33.245</td>\n",
              "      <td>47.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y_tilde_4[9856]</th>\n",
              "      <td>-130.014</td>\n",
              "      <td>232.234</td>\n",
              "      <td>-571.116</td>\n",
              "      <td>0.000</td>\n",
              "      <td>54.955</td>\n",
              "      <td>39.512</td>\n",
              "      <td>36.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y_tilde_4[9857]</th>\n",
              "      <td>-133.327</td>\n",
              "      <td>274.684</td>\n",
              "      <td>-518.343</td>\n",
              "      <td>0.000</td>\n",
              "      <td>39.221</td>\n",
              "      <td>27.900</td>\n",
              "      <td>116.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>1.23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39832 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    mean       sd   hdi_3%  hdi_97%  mcse_mean  mcse_sd  \\\n",
              "alpha[0]           1.318    1.711    0.040    4.170      0.212    0.150   \n",
              "alpha[1]           1.779    1.839    0.058    4.308      0.132    0.093   \n",
              "alpha[2]           1.484    2.154    0.054    4.634      0.162    0.115   \n",
              "alpha[3]           1.420    1.902    0.028    4.073      0.124    0.088   \n",
              "beta[0, 0]         0.757    2.532   -1.831    5.462      0.874    0.641   \n",
              "...                  ...      ...      ...      ...        ...      ...   \n",
              "Y_tilde_4[9853]  -93.933  157.830 -303.084    0.000     19.874   14.118   \n",
              "Y_tilde_4[9854] -109.316  193.856 -481.516    0.000     37.510   26.819   \n",
              "Y_tilde_4[9855] -139.886  276.712 -506.140    0.000     46.625   33.245   \n",
              "Y_tilde_4[9856] -130.014  232.234 -571.116    0.000     54.955   39.512   \n",
              "Y_tilde_4[9857] -133.327  274.684 -518.343    0.000     39.221   27.900   \n",
              "\n",
              "                 ess_bulk  ess_tail  r_hat  \n",
              "alpha[0]             17.0     602.0   1.17  \n",
              "alpha[1]             48.0     689.0   1.11  \n",
              "alpha[2]             18.0     307.0   1.16  \n",
              "alpha[3]            340.0     645.0   1.04  \n",
              "beta[0, 0]           14.0      42.0   1.22  \n",
              "...                   ...       ...    ...  \n",
              "Y_tilde_4[9853]      87.0      40.0   1.29  \n",
              "Y_tilde_4[9854]     127.0      44.0   1.33  \n",
              "Y_tilde_4[9855]      47.0      50.0   1.22  \n",
              "Y_tilde_4[9856]      36.0      22.0   1.31  \n",
              "Y_tilde_4[9857]     116.0      63.0   1.23  \n",
              "\n",
              "[39832 rows x 9 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "az.summary(fit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "az.plot_trace(fit, divergences=\"bottom\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# with open(\"data/lasso_model.pickle\", \"wb\") as f:\n",
        "#     pickle.dump(fit, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with open(\"data/lasso_model.pickle\", \"rb\") as f:\n",
        "#     foo = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNhM5fd+1LCNeYUr7Uf7oRe",
      "include_colab_link": true,
      "provenance": []
    },
    "interpreter": {
      "hash": "c627b44f4ae38c891954d455ae816164b6db6e9971d5361176b0256385e6703d"
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('bayes')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
